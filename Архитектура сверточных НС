Сверточные нейронные сети (CNN) особенно полезны для обработки изображений, так
как они могут выявлять пространственные связи, такие как края или текстуры.
Сверточный слой состоит из входных данных, обычно представленных как 3D-тензор
(высота, ширина, каналы, например, RGB), фильтров (небольших матриц, которые
скользят по изображению), операции свертки (вычисления скалярного произведения
для создания карт признаков), функции активации, такой как ReLU, для добавления
нелинейности, и слоя пулинга, часто max-pooling, который уменьшает размерность,
выбирая максимальное значение в небольших областях.
Параметры сверточного слоя, такие как размер фильтра (например, 3x3), количество
фильтров, шаг (stride) и заполнение (padding), определяют, как слой обрабатывает
входные данные и какие признаки извлекает. Max-pooling помогает снизить
вычислительную нагрузку и обеспечивает некоторую устойчивость к небольшим
смещениям изображения.
AlexNet (2012): Одна из первых глубоких CNN, победившая в конкурсе ImageNet, с 5
сверточными и 3 полносвязными слоями, использующая ReLU и dropout для
предотвращения переобучения.
VGG (2014): Показала важность глубины, используя 16 или 19 слоев с небольшими
фильтрами 3x3, что сделало сеть глубокой, но эффективной.
Inception (GoogLeNet, 2014): Ввела модули Inception, которые одновременно
применяют фильтры разных размеров для захвата признаков на разных масштабах, с
меньшим количеством параметров.
ResNet (2015): Использовала остаточные связи (skip connections), чтобы обучать очень
глубокие сети (до 152 слоев), решая проблему исчезающего градиента.
Трансферное обучение — это техника, при которой модель, предварительно обученная
на большом наборе данных, таком как ImageNet, дообучается на меньшем наборе
данных для конкретной задачи. Это позволяет использовать общие признаки,
изученные в нижних слоях сети, такие как края и текстуры, для новых задач, таких как
классификация медицинских изображений или распознавание лиц. Процесс включает
замораживание нижних слоев и обучение только верхних слоев или добавление новых
слоев, что значительно сокращает время обучения и улучшает результаты, особенно
при ограниченных данных.
