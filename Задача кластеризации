Кластеризация — это задача обучения без учителя, в которой необходимо разделить
набор данных на группы (кластеры) таким образом, чтобы объекты внутри одного
кластера были похожи друг на друга, а объекты из разных кластеров были как можно
более различны.

Кластеризация находит широкое применение в различных областях: от анализа
данных до компьютерного зрения и биоинформатики. Основные цели кластеризации
включают:
● Группировка объектов по схожести.
● Поиск аномалий в данных.
● Уменьшение размерности данных.

1. Алгоритмы кластеризации
К основным алгоритмам относятся:
● Алгоритм K-средних (K-Means)
● Иерархическая кластеризация
● Affinity Propagation

2. Алгоритм K-средних (K-Means)
K-средних — один из самых популярных и простых алгоритмов кластеризации,
основанный на идее разделения данных на K кластеров, минимизируя
внутрикластерное расстояние.

Как работает алгоритм K-средних:
1. Выбор числа кластеров (K): Определяется заранее количество кластеров, на
которое будет разделён набор данных.
2. Инициализация центроидов: Выбираются K случайных объектов из обучающего
набора данных в качестве начальных центроидов (средних) для каждого
кластера.
3. Присвоение точек кластерам: Каждой точке данных присваивается ближайший
кластер, используя меру расстояния (чаще всего используется евклидово
расстояние).
4. Пересчёт центроидов: После присвоения всех точек кластерам
пересчитываются новые центроиды для каждого кластера как среднее значение
всех точек, принадлежащих этому кластеру.
5. Повторение шагов 3 и 4: Этот процесс повторяется до тех пор, пока центроиды
не перестанут изменяться или изменятся незначительно.

Преимущества:
● Простой в реализации и быстродействующий на больших данных.
● Хорошо работает при условии, что кластеры имеют круглую или сферическую
форму.

Недостатки:
● Нужно заранее задать количество кластеров K, что не всегда очевидно.
● Неэффективен для кластеров с различной плотностью или сложной
геометрией.
● Очень чувствителен к начальной инициализации центроидов (для этого
применяется метод K-Means++).

3. Иерархическая кластеризация
Иерархическая кластеризация — это метод кластеризации, который создаёт
древовидную структуру кластеров, называемую дендрограммой. Этот метод не требует
заранее задавать количество кластеров и позволяет выбрать оптимальное количество
кластеров на основе дендрограммы.

Как работает иерархическая кластеризация:
1. Агломеративный подход: Каждая точка данных начинается как отдельный
кластер. Затем на каждом шаге два самых близких кластера объединяются в
один. Этот процесс продолжается, пока все объекты не будут объединены в
один кластер.
2. Дивизивный подход: Начинается с одного большого кластера, который затем
последовательно делится на более мелкие кластеры.
3. Мера сходства: Для определения схожести между кластерами обычно
используется евклидово расстояние, но могут быть использованы и другие
меры, такие как манхэттенское расстояние или корреляция.

Преимущества:
● Не требует предварительного задания числа кластеров.
● Подходит для сложных структур данных, когда необходимо построить иерархию
или вложенные кластеры.

Недостатки:
● Алгоритм может быть медленным при больших объёмах данных (из-за
вычисления расстояний между всеми парами объектов).
● Сложно выбрать оптимальное количество кластеров, хотя это можно сделать с
помощью дендрограммы.

Типы связей:
● Ссылка по минимальному расстоянию (single linkage): расстояние между двумя
кластерами — это минимальное расстояние между любыми двумя объектами
из разных кластеров.
● Ссылка по максимальному расстоянию (complete linkage): расстояние между
двумя кластерами — это максимальное расстояние между любыми двумя
объектами из разных кластеров.
● Среднее расстояние (average linkage): расстояние между двумя кластерами —
это среднее расстояние между всеми парами объектов из разных кластеров.

4. Affinity Propagation
Affinity Propagation — это более современный алгоритм кластеризации, который, в
отличие от алгоритма K-средних, не требует задания числа кластеров заранее. Он
использует все данные для определения центроидов и объединяет похожие точки в
кластеры на основе "передачи схожести".

Как работает Affinity Propagation:
1. Передача схожести: Каждый объект в данных передаёт схожесть всем другим
объектам. Для этого используется матрица схожести (например, основанная на
расстоянии между точками).
2. Два типа сообщений:
○ Сообщения о предпочтении: У каждого объекта есть свой
"предпочтительный центроид", и объект сообщает другим объектам,
насколько он бы хотел быть центроидом.
○ Сообщения о схожести: Каждый объект отправляет сообщения другим
объектам, указывая, насколько он похож на них.
3. Обновление сообщений: Процесс передачи и обновления сообщений
продолжается до тех пор, пока не достигнется сходимость — каждый объект
либо становится центроидом, либо назначает другой объект как его центроид.

Преимущества:
● Не требует задания числа кластеров заранее.
● Может работать с различной плотностью кластеров.

Недостатки:
● Может быть более медленным, чем другие алгоритмы, особенно при большом
количестве данных.
● Требует значительных вычислительных ресурсов для обработки больших
наборов данных.
