Полносвязные нейронные сети (Fully Connected Neural Networks) представляют собой фундаментальный тип искусственных нейронных сетей, где каждый нейрон текущего слоя соединен со всеми нейронами последующего слоя. В контексте TensorFlow/Keras такие сети реализуются преимущественно через слой Dense.

Ключевые характеристики архитектуры:
- Последовательное соединение слоев (feed-forward)
- Полная связность между соседними слоями
- Наличие нелинейных функций активации
- Возможность глубокой иерархии (множество скрытых слоев)

Базовые компоненты реализации в Keras
При построении FCNN в Keras используются следующие основные элементы:
- Слои Dense:
 - Основной строительный блок FCNN
 - Реализует операцию: output = activation(dot(input, kernel) + bias)
 - Требует указания количества нейронов и функции активации
- Функции активации:
 - ReLU: наиболее распространена для скрытых слоев
 - Sigmoid/Tanh: в специфических случаях
 - Softmax: исключительно для выходного слоя при классификации
 - Linear: для задач регрессии
- Модельные API:
 - Sequential API: линейная композиция слоев
 - Functional API: поддержка сложных топологий

Принципы решения задач регрессии
Для задач регрессионного анализа FCNN в Keras настраиваются следующим образом:
Архитектурные особенности:
- Выходной слой содержит один нейрон (для скалярного вывода)
- Используется линейная активация (или отсутствие активации)
- Глубина сети зависит от сложности задачи
Функции потерь:
- Среднеквадратичная ошибка (MSE) - основной выбор
- Средняя абсолютная ошибка (MAE) при наличии выбросов

Метрики оценки:
- R-квадрат (коэффициент детерминации)
- Среднеквадратичное отклонение
- Средняя абсолютная процентная ошибка

Принципы решения задач классификации
Применение FCNN для классификационных задач имеет свои особенности:
- Архитектурные различия:
 - Количество выходных нейронов равно числу классов
 - Softmax-активация для многоклассовой классификации
 - Sigmoid-активация для бинарной классификации
- Функции потерь:
 - Binary crossentropy: бинарная классификация
 - Categorical crossentropy: one-hot кодировка классов
 - Sparse categorical crossentropy: целочисленные метки
- Оценочные метрики:
 - Accuracy (доля правильных ответов)
 - Precision/Recall для несбалансированных данных
 - AUC-ROC для оценки качества бинарных классификаторов

Процесс обучения и оптимизации
Обучение FCNN в TensorFlow/Keras включает несколько ключевых аспектов:
- Механизм обратного распространения:
 - Автоматическое дифференцирование
 - Вычисление градиентов по цепному правилу
 - Пакетная обработка (batch processing)
- Оптимизаторы:
 - SGD с различными модификациями
 - Adam как наиболее универсальный выбор
 - RMSprop для задач с шумными градиентами
- Регуляризация:
 - L1/L2 регуляризация весов
 - Dropout-слои для предотвращения переобучения
 - Early stopping по валидационному набору

При работе с FCNN в TensorFlow/Keras следует учитывать:

Предобработка данных:
- Нормализация/стандартизация входных признаков
- Кодировка категориальных переменных
- Балансировка классов для классификации

Настройка гиперпараметров:
- Количество слоев и нейронов
- Скорость обучения (learning rate)
- Размер пакета (batch size)

Интерпретация результатов:
- Анализ кривых обучения
- Проверка на переобучение
